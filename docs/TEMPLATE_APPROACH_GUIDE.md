# Template Approach for Multiple Graph Generation

## ğŸ“‹ ê°œìš”

**ë¬¸ì œì :**
- ì‚¬ìš©ì: "ê° Techë³„ë¡œ CPK íŠ¸ë Œë“œë¥¼ ë¶„ë¦¬í•´ì„œ ë¼ì¸ê·¸ë˜í”„ ë³´ì—¬ì¤˜"
- LLM: Tech ì»¬ëŸ¼ì— ì–´ë–¤ ê°’ë“¤ì´ ìˆëŠ”ì§€ ëª¨ë¦„ (Tech_A, Tech_B, ...?)
- ë©”íƒ€ë°ì´í„°ì— ê³ ìœ ê°’ì„ ëª¨ë‘ í¬í•¨í•˜ê¸°ì—” ë„ˆë¬´ ë§ì„ ìˆ˜ ìˆìŒ (100ê°œ ì´ìƒ)
- í”„ë¡¬í”„íŠ¸ í† í° ì œí•œ

**í•´ê²°ì±…: Template Approach**
- LLM: í…œí”Œë¦¿ 1ê°œ ìƒì„± + `split_by` í•„ë“œ ì§€ì • + `{{SPLIT_VALUE}}` í”Œë ˆì´ìŠ¤í™€ë” ì‚¬ìš©
- Backend: ì‹¤ì œ ê³ ìœ ê°’ ì¶”ì¶œ â†’ í…œí”Œë¦¿ í™•ì¥ â†’ `graph_specs` ë°°ì—´ ìƒì„±
- Frontend: í™•ì¥ëœ `graph_specs` ë°°ì—´ ë Œë”ë§

---

## ğŸ¯ ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ ë¹„êµ

### Option A: Template Approach â­ RECOMMENDED (ì¹´í…Œê³ ë¦¬ ê°’ë³„ ë¶„ë¦¬)

**Use case:** "ê° Techë³„ë¡œ", "ê° ì¥ë¹„ë³„ë¡œ", "ê° DEVICEë§ˆë‹¤"

| ì—­í•  | ì±…ì„ |
|------|------|
| LLM | í…œí”Œë¦¿ 1ê°œ ìƒì„± + `split_by` ì§€ì • |
| Backend | ê³ ìœ ê°’ ì¶”ì¶œ + í…œí”Œë¦¿ í™•ì¥ â†’ `graph_specs` |
| Frontend | `graph_specs` ë°°ì—´ ë Œë”ë§ |

**ì¥ì :**
- âœ… LLMì€ ê³ ìœ ê°’ì„ ëª°ë¼ë„ ë¨
- âœ… í† í° ì ˆì•½
- âœ… ê³ ìœ ê°’ì´ 100ê°œì—¬ë„ ë¬¸ì œì—†ìŒ
- âœ… Backendì—ì„œ ê°œìˆ˜ ì œí•œ ê°€ëŠ¥

**ë‹¨ì :**
- âŒ Backend ì²˜ë¦¬ ë¡œì§ ì¶”ê°€ í•„ìš”
- âŒ í”Œë ˆì´ìŠ¤í™€ë” ì¹˜í™˜ ë¡œì§ êµ¬í˜„ í•„ìš”

### Option B: Direct Array Approach (ì»¬ëŸ¼ë³„ ë¶„ë¦¬)

**Use case:** "WIDTH, THICKNESS, DEPTH ê°ê°"

| ì—­í•  | ì±…ì„ |
|------|------|
| LLM | `graph_specs` ë°°ì—´ ì§ì ‘ ìƒì„± (ëª¨ë“  ìŠ¤í™ í¬í•¨) |
| Backend | LLM ì‘ë‹µ ê·¸ëŒ€ë¡œ ì‚¬ìš© |
| Frontend | `graph_specs` ë°°ì—´ ë Œë”ë§ |

**ì¥ì :**
- âœ… Backend ì²˜ë¦¬ ê°„ë‹¨
- âœ… LLMì´ ì§ì ‘ ì œì–´

**ë‹¨ì :**
- âŒ ì»¬ëŸ¼ëª…ì´ ë§ìœ¼ë©´ LLM ì‘ë‹µ ê¸¸ì–´ì§
- âŒ ê°’ë³„ ë¶„ë¦¬ì—ëŠ” ì‚¬ìš© ë¶ˆê°€

---

## ğŸ“ Template Approach ìƒì„¸ ê°€ì´ë“œ

### 1. LLM Response Format

```json
{
  "data": {
    "analysis_type": "line_graph",
    "real_data": [ ... ],  // ëª¨ë“  ë°ì´í„° í¬í•¨
    "graph_spec_template": {
      "schema_version": "1.0",
      "chart_type": "line_graph",
      "split_by": "TECH",  // ì´ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„ë¦¬
      "dataset_index": 0,
      "encodings": {
        "x": { "field": "DATE", "type": "temporal" },
        "y": { "field": "CPK", "type": "quantitative" }
      },
      "transforms": [
        { 
          "type": "filter", 
          "field": "TECH", 
          "op": "==", 
          "value": "{{SPLIT_VALUE}}"  // í”Œë ˆì´ìŠ¤í™€ë”
        },
        { "type": "sort", "field": "DATE", "direction": "asc" }
      ],
      "layout": {
        "title": "{{SPLIT_VALUE}} CPK Trend",  // í”Œë ˆì´ìŠ¤í™€ë”
        "height": 400
      }
    }
  }
}
```

**Key Fields:**
- `graph_spec_template`: í…œí”Œë¦¿ ê°ì²´ (graph_specsê°€ ì•„ë‹˜!)
- `split_by`: ë¶„ë¦¬ ê¸°ì¤€ ì»¬ëŸ¼ëª…
- `{{SPLIT_VALUE}}`: ì‹¤ì œ ê°’ìœ¼ë¡œ ì¹˜í™˜ë  í”Œë ˆì´ìŠ¤í™€ë”

### 2. Backend Processing Logic

```python
import json
import copy

def expand_graph_spec_template(response_data, df):
    """
    graph_spec_templateì„ graph_specs ë°°ì—´ë¡œ í™•ì¥
    
    Args:
        response_data: LLM ì‘ë‹µ ë°ì´í„°
        df: pandas DataFrame (ì‹¤ì œ ë°ì´í„°)
    
    Returns:
        ìˆ˜ì •ëœ response_data (graph_specs í¬í•¨)
    """
    # 1. í…œí”Œë¦¿ ì¶”ì¶œ
    if "graph_spec_template" not in response_data:
        return response_data  # í…œí”Œë¦¿ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    
    template = response_data["graph_spec_template"]
    
    # 2. split_by ì»¬ëŸ¼ ì¶”ì¶œ
    if "split_by" not in template:
        # split_byê°€ ì—†ìœ¼ë©´ ë‹¨ì¼ ìŠ¤í™ìœ¼ë¡œ ì²˜ë¦¬
        response_data["graph_spec"] = template
        del response_data["graph_spec_template"]
        return response_data
    
    split_column = template["split_by"]
    
    # 3. ê³ ìœ ê°’ ì¶”ì¶œ (ìµœëŒ€ 10ê°œë¡œ ì œí•œ)
    if split_column not in df.columns:
        raise ValueError(f"Column '{split_column}' not found in dataframe")
    
    unique_values = df[split_column].unique()
    
    # ì„±ëŠ¥ì„ ìœ„í•´ ìµœëŒ€ 10ê°œë¡œ ì œí•œ
    MAX_GRAPHS = 10
    if len(unique_values) > MAX_GRAPHS:
        print(f"Warning: {len(unique_values)} unique values found, limiting to {MAX_GRAPHS}")
        unique_values = unique_values[:MAX_GRAPHS]
    
    # 4. ê° ê°’ì— ëŒ€í•´ ìŠ¤í™ ìƒì„±
    graph_specs = []
    
    for value in unique_values:
        # í…œí”Œë¦¿ ë³µì‚¬ (deep copy)
        spec = copy.deepcopy(template)
        
        # split_by í•„ë“œ ì œê±° (í”„ë¡ íŠ¸ì—”ë“œì— ë¶ˆí•„ìš”)
        if "split_by" in spec:
            del spec["split_by"]
        
        # {{SPLIT_VALUE}} í”Œë ˆì´ìŠ¤í™€ë” ì¹˜í™˜
        spec_str = json.dumps(spec)
        spec_str = spec_str.replace("{{SPLIT_VALUE}}", str(value))
        spec = json.loads(spec_str)
        
        graph_specs.append(spec)
    
    # 5. ì‘ë‹µ ë°ì´í„° ìˆ˜ì •
    response_data["graph_specs"] = graph_specs
    del response_data["graph_spec_template"]
    
    # Success ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
    response_data["success_message"] = (
        f"âœ… {len(graph_specs)}ê°œì˜ {response_data['analysis_type']} ìƒì„± ì™„ë£Œ"
    )
    
    return response_data


# ì‚¬ìš© ì˜ˆì‹œ
def process_llm_response(llm_response, df):
    """LLM ì‘ë‹µ í›„ì²˜ë¦¬"""
    response_data = llm_response.get("data", {})
    
    # í…œí”Œë¦¿ í™•ì¥
    response_data = expand_graph_spec_template(response_data, df)
    
    return {"data": response_data}
```

### 3. Complete Backend Flow

```python
from typing import Dict, Any
import pandas as pd

def generate_excel_analysis_response(
    df: pd.DataFrame,
    user_request: str,
    llm_api_func
) -> Dict[str, Any]:
    """
    ì—‘ì…€ ë°ì´í„° ë¶„ì„ ì‘ë‹µ ìƒì„± (í…œí”Œë¦¿ ì§€ì›)
    
    Args:
        df: pandas DataFrame
        user_request: ì‚¬ìš©ì ìš”ì²­
        llm_api_func: LLM API í˜¸ì¶œ í•¨ìˆ˜
    
    Returns:
        í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ì†¡í•  ìµœì¢… ì‘ë‹µ
    """
    # 1. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    column_metadata = extract_column_metadata(df)
    sample_data = df.head(5).to_dict('records')
    
    # 2. ë‹¤ì¤‘ ê·¸ë˜í”„ ì—¬ë¶€ íŒë‹¨
    is_multiple = should_create_multiple_graphs(user_request, column_metadata)
    
    # 3. LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
    if is_multiple:
        # ê°’ë³„ ë¶„ë¦¬ì¸ì§€ ì»¬ëŸ¼ë³„ ë¶„ë¦¬ì¸ì§€ íŒë‹¨
        if is_value_based_split(user_request):
            prompt = get_template_prompt(column_metadata, user_request)
        else:
            prompt = get_array_prompt(column_metadata, user_request)
    else:
        prompt = get_single_graph_prompt(column_metadata, user_request)
    
    # 4. LLM API í˜¸ì¶œ
    llm_response = llm_api_func(prompt)
    
    # 5. ì‘ë‹µ íŒŒì‹±
    response_data = {
        "analysis_type": llm_response.get("chart_type", "line_graph"),
        "real_data": [df.to_dict("records")],
        "file_name": "analysis.xlsx",
        "summary": llm_response.get("summary", ""),
        "success_message": "âœ… ë¶„ì„ ì™„ë£Œ"
    }
    
    # 6. graph_spec_template ë˜ëŠ” graph_specs ì¶”ê°€
    if "graph_spec_template" in llm_response:
        response_data["graph_spec_template"] = llm_response["graph_spec_template"]
    elif "graph_specs" in llm_response:
        response_data["graph_specs"] = llm_response["graph_specs"]
    elif "graph_spec" in llm_response:
        response_data["graph_spec"] = llm_response["graph_spec"]
    
    # 7. í…œí”Œë¦¿ í™•ì¥ (ìˆëŠ” ê²½ìš°)
    response_data = expand_graph_spec_template(response_data, df)
    
    # 8. ìµœì¢… ì‘ë‹µ ë°˜í™˜
    return {"data": response_data}


def should_create_multiple_graphs(user_request: str, metadata: dict) -> bool:
    """ë‹¤ì¤‘ ê·¸ë˜í”„ ìƒì„± ì—¬ë¶€ íŒë‹¨"""
    keywords = ["ê°ê°", "ê°", "ë¶„ë¦¬", "ë³„ë„", "ë‚˜ëˆ ì„œ", "ê°œë³„", "ë”°ë¡œ"]
    return any(keyword in user_request for keyword in keywords)


def is_value_based_split(user_request: str) -> bool:
    """ê°’ë³„ ë¶„ë¦¬ (í…œí”Œë¦¿ í•„ìš”) vs ì»¬ëŸ¼ë³„ ë¶„ë¦¬ (ë°°ì—´ ì§ì ‘ ìƒì„±)"""
    # "ê° XXXë³„ë¡œ" íŒ¨í„´ â†’ ê°’ë³„ ë¶„ë¦¬
    value_patterns = ["ë³„ë¡œ", "ë§ˆë‹¤", "ê°ê°"]
    
    # "WIDTH, THICKNESS" ê°™ì´ ì»¬ëŸ¼ ë‚˜ì—´ â†’ ì»¬ëŸ¼ë³„ ë¶„ë¦¬
    column_patterns = [",", "ì™€", "ê³¼", "ê·¸ë¦¬ê³ "]
    
    has_value_pattern = any(p in user_request for p in value_patterns)
    has_column_pattern = any(p in user_request for p in column_patterns)
    
    # ê°’ë³„ íŒ¨í„´ì´ ìˆê³  ì»¬ëŸ¼ ë‚˜ì—´ì´ ì—†ìœ¼ë©´ ê°’ë³„ ë¶„ë¦¬
    return has_value_pattern and not has_column_pattern
```

### 4. Placeholder Replacement Rules

**ì§€ì›í•˜ëŠ” í”Œë ˆì´ìŠ¤í™€ë”:**

| í”Œë ˆì´ìŠ¤í™€ë” | ì„¤ëª… | ì˜ˆì‹œ |
|-------------|------|------|
| `{{SPLIT_VALUE}}` | split_by ì»¬ëŸ¼ì˜ ì‹¤ì œ ê°’ | "Tech_A", "EQ01" |
| `{{SPLIT_COLUMN}}` | split_by ì»¬ëŸ¼ëª… | "TECH", "EQ" |

**ì¹˜í™˜ ìœ„ì¹˜:**
- âœ… `transforms[].value`
- âœ… `layout.title`
- âœ… `layout.xaxis.title`
- âœ… `layout.yaxis.title`
- âœ… ê¸°íƒ€ ëª¨ë“  ë¬¸ìì—´ í•„ë“œ

**ì˜ˆì‹œ:**
```json
// Before (template)
{
  "title": "{{SPLIT_VALUE}} Analysis for {{SPLIT_COLUMN}}",
  "transforms": [
    { "field": "TECH", "value": "{{SPLIT_VALUE}}" }
  ]
}

// After (TECH = "Tech_A")
{
  "title": "Tech_A Analysis for TECH",
  "transforms": [
    { "field": "TECH", "value": "Tech_A" }
  ]
}
```

---

## ğŸš€ ì‹¤ì „ ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ì¹´í…Œê³ ë¦¬ ê°’ë³„ ë¶„ë¦¬

**ì‚¬ìš©ì ìš”ì²­:** "ê° Techë³„ë¡œ CPK íŠ¸ë Œë“œë¥¼ ë¶„ë¦¬í•´ì„œ ë¼ì¸ê·¸ë˜í”„ ë³´ì—¬ì¤˜"

**LLM ì‘ë‹µ:**
```json
{
  "graph_spec_template": {
    "split_by": "TECH",
    "chart_type": "line_graph",
    "encodings": {
      "x": { "field": "DATE" },
      "y": { "field": "CPK" }
    },
    "transforms": [
      { "type": "filter", "field": "TECH", "op": "==", "value": "{{SPLIT_VALUE}}" }
    ],
    "layout": {
      "title": "{{SPLIT_VALUE}} CPK Trend"
    }
  }
}
```

**Backend ì²˜ë¦¬:**
```python
df["TECH"].unique()  # ['Tech_A', 'Tech_B', 'Tech_C']

# í…œí”Œë¦¿ í™•ì¥ ê²°ê³¼
graph_specs = [
  { "chart_type": "line_graph", "transforms": [{"value": "Tech_A"}], "layout": {"title": "Tech_A CPK Trend"} },
  { "chart_type": "line_graph", "transforms": [{"value": "Tech_B"}], "layout": {"title": "Tech_B CPK Trend"} },
  { "chart_type": "line_graph", "transforms": [{"value": "Tech_C"}], "layout": {"title": "Tech_C CPK Trend"} }
]
```

**Frontend ë Œë”ë§:** 3ê°œì˜ ë¼ì¸ê·¸ë˜í”„

---

### ì˜ˆì‹œ 2: ì»¬ëŸ¼ë³„ ë¶„ë¦¬ (í…œí”Œë¦¿ ë¶ˆí•„ìš”)

**ì‚¬ìš©ì ìš”ì²­:** "WIDTH, THICKNESS, DEPTH ê°ê°ì— ëŒ€í•´ ì¥ë¹„ë³„ íŠ¸ë Œë“œ"

**LLM ì‘ë‹µ:** (í…œí”Œë¦¿ ì—†ì´ ì§ì ‘ ë°°ì—´)
```json
{
  "graph_specs": [
    { "encodings": { "y": { "field": "WIDTH" } }, "layout": { "title": "WIDTH Trend" } },
    { "encodings": { "y": { "field": "THICKNESS" } }, "layout": { "title": "THICKNESS Trend" } },
    { "encodings": { "y": { "field": "DEPTH" } }, "layout": { "title": "DEPTH Trend" } }
  ]
}
```

**Backend ì²˜ë¦¬:** ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë³€í™˜ ë¶ˆí•„ìš”)

**Frontend ë Œë”ë§:** 3ê°œì˜ ë¼ì¸ê·¸ë˜í”„

---

## âš™ï¸ ì„¤ì • ë° ìµœì í™”

### ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­

```python
# config.py
MAX_GRAPHS_PER_REQUEST = 10  # ìµœëŒ€ ê·¸ë˜í”„ ê°œìˆ˜ ì œí•œ
TEMPLATE_CACHE_TTL = 300      # í…œí”Œë¦¿ ìºì‹œ TTL (ì´ˆ)
UNIQUE_VALUES_LIMIT = 15      # ê³ ìœ ê°’ ì œí•œ (ê²½ê³  í‘œì‹œ)

def expand_graph_spec_template_optimized(response_data, df, config):
    """ìµœì í™”ëœ í…œí”Œë¦¿ í™•ì¥"""
    template = response_data["graph_spec_template"]
    split_column = template["split_by"]
    
    # 1. ê³ ìœ ê°’ ê°œìˆ˜ ì²´í¬
    unique_values = df[split_column].unique()
    
    if len(unique_values) > config.UNIQUE_VALUES_LIMIT:
        # ê²½ê³  ë¡œê·¸ + ìƒìœ„ Nê°œë§Œ ì„ íƒ
        logger.warning(
            f"Too many unique values ({len(unique_values)}) for column '{split_column}'. "
            f"Limiting to top {config.MAX_GRAPHS_PER_REQUEST}."
        )
        # ë¹ˆë„ìˆ˜ ê¸°ì¤€ ìƒìœ„ Nê°œ ì„ íƒ
        top_values = df[split_column].value_counts().head(config.MAX_GRAPHS_PER_REQUEST).index
        unique_values = top_values
    else:
        unique_values = unique_values[:config.MAX_GRAPHS_PER_REQUEST]
    
    # 2. í…œí”Œë¦¿ í™•ì¥
    # ... (ë™ì¼)
```

### ì—ëŸ¬ ì²˜ë¦¬

```python
def expand_graph_spec_template_safe(response_data, df):
    """ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨ í…œí”Œë¦¿ í™•ì¥"""
    try:
        if "graph_spec_template" not in response_data:
            return response_data
        
        template = response_data["graph_spec_template"]
        
        # split_by ê²€ì¦
        if "split_by" not in template:
            logger.error("Missing 'split_by' field in template")
            # Fallback: ë‹¨ì¼ ê·¸ë˜í”„ë¡œ ë³€í™˜
            response_data["graph_spec"] = template
            del response_data["graph_spec_template"]
            return response_data
        
        split_column = template["split_by"]
        
        # ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ ê²€ì¦
        if split_column not in df.columns:
            logger.error(f"Column '{split_column}' not found in dataframe")
            # Fallback: ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
            response_data["error"] = f"ì»¬ëŸ¼ '{split_column}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            return response_data
        
        # ì •ìƒ ì²˜ë¦¬
        return expand_graph_spec_template(response_data, df)
        
    except Exception as e:
        logger.exception("Error expanding template")
        response_data["error"] = f"ê·¸ë˜í”„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        return response_data
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [excel_analysis_response_formats.md](./excel_analysis_response_formats.md) - ì‘ë‹µ í˜•ì‹ ì „ì²´ ê°€ì´ë“œ
- [llm_prompts_for_plotly_spec_generation.md](./llm_prompts_for_plotly_spec_generation.md) - LLM í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
- [SUMMARY_multiple_graphs_support.md](./SUMMARY_multiple_graphs_support.md) - ë‹¤ì¤‘ ê·¸ë˜í”„ ì§€ì› ìš”ì•½

---

**ì‘ì„±ì¼:** 2025-12-05  
**ë²„ì „:** 1.0
